\chapter{Phương Thức}
\label{chap:Phương Thức}

Trong chương này, chúng tôi sẽ trình bày phương thức chuẩn bị dữ liệu hội thoại, 

\section{Chuẩn Bị Dữ Liệu}

Chúng ta xác định một cuộc trò chuyện $C=\{ \left(u_{i}, y_{i}\right)\}_{i=1}^{L}$, trong đó $L$ là số lượng các câu nói trong cuộc trò chuyện, $u_{i}$ là câu nói thứ $i^{th}$ trong $C$ và $y_{i}$ là nhãn đúng của $u_{i}$. 
Ở đây, $y_{i} \in \left\{1,2,\cdots, c\right\}$ và $c$ là tổng số nhãn. 
Mỗi câu nói $u_{i}$ của người nói $p_{s(u_i)}$, trong đó hàm $s(\cdot)$ ánh xạ chỉ số của câu nói vào người nói tương ứng. 

Cho mỗi câu nói $u_{i}$, chúng ta trích xuất đặc trưng đa mô hình $x_{i}=\{{x}_{i}^m\}_{m\in\{a, l, v\}}$. 
Ở đây, $x_{i}^a \in \mathbb{R}^{d_a}$, $x_{i}^l \in \mathbb{R}^{d_l}$ and $x_{i}^v \in \mathbb{R}^{d_v}$ là các đặc trưng mức câu nói của các mô hình âm thanh, từ vựng và hình ảnh tương ứng.
Và $\{d_{m}\}_{m\in\{a, l, v\}}$ là chiều của đặc trưng của mỗi mô hình.

Để tạo ra các trường hợp mất mô hình giống như trong thế giới thực, chúng ta sẽ loại bỏ ngẫu nhiên một số mô hình, nhưng đảm bảo ít nhất có một mô hình cho mỗi mẫu, theo các công trình trước đó.

% \cite{chen2020hgmf, zhang2022deep}. - có cite

Do đó, một tập dữ liệu $M$ không hoàn thiện có $\left(2^{M}-1\right)$ mẫu thiếu sót khác nhau. 
Hình \ref{Figure2} minh họa một tập dữ liệu trimodal ($M=3$) với bảy mẫu thiếu sót. 
Giả sử $\sigma_{i}$ là mẫu thiếu sót của $u_{i}$ và $\phi(\cdot)$ là một hàm mô tả mỗi mẫu thiếu sót với các chế độ có sẵn. 
Biểu diễn không hoàn thiện của $u_{i}$ được đánh dấu là $\widetilde{x}_{i}=\{{\lambda}_{i}^m{x}_{i}^m\}_{m\in\{a, l, v\}}$, trong đó ${\lambda}_{i}^m$ được định nghĩa như sau:

\begin{equation}
	\label{eq1}
	{\lambda}_{i}^m=\begin{cases}
	1, m\in\phi(\sigma_{i}) \\
	0, m\notin\phi(\sigma_{i}) \\
	\end{cases}
\end{equation}




\section{Mã Hoá Thông Tin Ngữ Cảnh} 

Như đã đề cập ở trên, thông tin ngữ cảnh hội thoại là quan trọng để dự đoán nhãn cảm xúc của mỗi lời nói. Vì vậy, việc mã hóa thông tin ngữ cảnh vào biểu diễn tính năng của lời nói là có lợi. Chúng ta tạo ra mã hóa tính năng của lời nói được nhận thông tin ngữ cảnh cho mỗi modality qua mã hóa modality tương ứng. Cụ thể, chúng ta sử dụng mạng LSTM kết hợp hai chiều để mã hóa thông tin ngữ cảnh liên tục cho modality văn bản. Đối với modality âm thanh và hình ảnh, chúng ta sử dụng mạng kết nối đầy đủ. Mã hóa tính năng của lời nói được nhận thông tin ngữ cảnh có thể biểu diễn như sau:

\begin{small}
\begin{equation}
\begin{aligned}
    \centering
    &h_{i}^t = [\overrightarrow{\mathrm{LSTM}}(u_{i}^t,h_{i-1}^t),\overleftarrow{\mathrm{LSTM}}(u_{i}^t,h_{i+1}^t)] \\
    &h_{i}^a = W_{e}^a u_{i}^a+b_{i}^a \\
    &h_{i}^v = W_{e}^v u_{i}^v+b_{i}^v
\end{aligned}
\end{equation}
\end{small}
trong đó $u_{i}^a$, $u_{i}^v$ , $u_{i}^t$  là biểu diễn tính năng thô cảnh của câu thoại $i$ từ modality âm thanh, hình ảnh và văn bản, tương ứng. Mã hóa modality xuất ra mã hóa tính năng thô cảnh cho các modality $h_{i}^a$, $h_{i}^v$, and $h_{i}^t$ tương ứng.




\section*{Missing Mask}

\section*{Feature Propagation}

\paragraph{Feature Propagation Algorithm.}
We can notice that the update in Equation \ref{eq:dirichlet_iteration} is equivalent to first multiplying the feature vector $\mathbf{x}$ by the original diffusion matrix $\tilde{\mathbf{A}}$, and then resetting the known features to their true value. This gives us Algorithm \ref{alg:fp}, an extremely simple and scalable iterative algorithm to reconstruct the missing features on a graph, which we refer to as {\em Feature Propagation} (FP). While $\mathbf{x}_u$ can be initialized to any value, in practice we initialize $\mathbf{x}_u$ to zero and find 40 iterations to be enough to provide convergence for all datasets we experimented on. At each iteration, the diffusion occurs from the nodes with known features to the nodes with unknown features as well as among the nodes with unknown features. 

\paragraph{Extension to Vector-Valued Features.}
Algorithm \ref{alg:fp} extends seamlessly to vector-valued features by simply replacing the feature vector $\mathbf{x}$ with a $n \times d$ feature matrix $\mathbf{X}$, where $d$ is the number of features. Multiplying the diffusion matrix $\mathbf{A}$ by the feature matrix $\mathbf{X}$ diffuses each feature channel independently. Interestingly, it would not be trivial to extend Equation \ref{eq:dirichlet_iteration} to vector-valued features without noticing its equivalence with Algorithm \ref{alg:fp}, as each node could have different missing features, leading to different sub-matrices $\tilde{\mathbf{A}}_{uk}$ and $\tilde{\mathbf{A}}_{uu}$ for each feature channel.

\paragraph{Learning.}
One significant advantage of FP is that it can be easily combined with any graph learning model to generate predictions for the downstream task. Moreover, FP is not aimed at merely reconstructing the node features. Instead, by only reconstructing the lower frequency components of the signal, it is by design very well suited to be combined with GNNs, which are known to mainly leverage these lower frequency components~\citep{pmlr-v97-wu19e}.
Our approach is generic and can be used for any graph-related task for missing features, such as node classification, link prediction and graph classification. In this paper, we focus on node classification.

\paragraph{Oversmoothing.}
Figure \ref{fig:spectral_reconstruction} shows that the more features are missing, the smoother the reconstruction produced by FP is. Despite this, FP does not suffer from oversmoothing~\citep{oono2020graph}, a term used when node representations converge to similar values. Oversmoothing is caused by repeated diffusion and occurs widely when stacking more than a few layers of the most popular GNNs such as GCN~\citep{Kipf:2016tc}, GAT~\citep{velickovic2018graph} or SGC~\citep{pmlr-v97-wu19e}. However, the boundary conditions in the Feature Propagation diffusion equation prevent the reconstructed features from becoming overly smooth, even when using an extremely high number of diffusion steps. This has also been studied by CGNN~\citep{10.5555/3524938.3525904} and GRAND++~\citep{thorpe2022grand}, which require soft boundary conditions in the form of a source term to prevent oversmoothing, although not in the context of missing features. 



\section{Graph Attentional Layer}

Lorem Ipsum

\section{Phân Lớp}

Dựa theo phần ***,  chúng tôi khởi tạo các nút bằng kết hợp của đặc trưng của câu nói và đặc trưng người nói, được biểu diễn là $h^{'}_{i}$.

% TODO: Reference về phần tạo Graph: sec.~\ref{sec:graph}

\begin{small}
\begin{equation}
    \centering
    h^{'}_{i} = [h^{'a}_{i}, h^{'v}_{i}, h^{'t}_{i}].
\end{equation}
\end{small}
Gọi $g_{i}^a$, $g_{i}^v$ và $g_{i}^t$ là các đặc trưng của các mô hình khác nhau được mã hóa bởi GCN. Các đặc trưng tương ứng với cùng một câu thoại được nối lại: 

\begin{small}
\begin{equation}
    \centering
    g_{i} = [g_{i}^a, g_{i}^v, g_{i}^t].
\end{equation}
\end{small}
Chúng ta sau đó có thể nối lại $g_{i}$ và $h_{i}$ để tạo ra biểu diễn đặc trưng cuối cùng cho mỗi câu nói: 

\begin{small}
\begin{align}
    \centering
    &e_{i} = [h^{'}_{i}, g_{i}] ,
\end{align}
\end{small}

Sau đó, $e_{i}$  được cho vào một MLP với các lớp đầy đủ được kết nối để dự đoán nhãn cảm xúc $\hat{y_{i}}$ cho câu thoại:

\begin{small}
\begin{equation}
\begin{aligned}
    &l_{i} = RELU(W_{l}e_{i}+b_{l})\\
    &P_{i} = Softmax(W_{smax}l_{i}+b_{smax})\\
    &\hat{y_{i}} = \mathop{\arg\min}_{k} (P_{i}[k])
\end{aligned}
\end{equation}
\end{small}


